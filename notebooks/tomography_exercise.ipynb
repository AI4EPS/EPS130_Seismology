{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Seismic Tomography — Exercises\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/AI4EPS/EPS130_Seismology/blob/main/notebooks/tomography_exercise.ipynb\">\n",
    "<img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "\n",
    "Complete the following exercises to practice the concepts from the tomography lecture.\n",
    "\n",
    "**Key equations:**\n",
    "\n",
    "| Formula | When to use |\n",
    "|---------|-------------|\n",
    "| $\\mathbf{m} = (\\mathbf{G}^T \\mathbf{G})^{-1} \\mathbf{G}^T \\mathbf{d}$ | Least-squares inversion (no regularization) |\n",
    "| $\\mathbf{m} = (\\mathbf{G}^T \\mathbf{G} + \\alpha^2 \\mathbf{L}^T \\mathbf{L})^{-1} \\mathbf{G}^T \\mathbf{d}$ | Regularized inversion (smoothing) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: netCDF4 in /Users/weiqiang/.local/miniconda3/lib/python3.12/site-packages (1.7.4)\n",
      "Requirement already satisfied: cartopy in /Users/weiqiang/.local/miniconda3/lib/python3.12/site-packages (0.25.0)\n",
      "Requirement already satisfied: cftime in /Users/weiqiang/.local/miniconda3/lib/python3.12/site-packages (from netCDF4) (1.6.5)\n",
      "Requirement already satisfied: certifi in /Users/weiqiang/.local/miniconda3/lib/python3.12/site-packages (from netCDF4) (2026.1.4)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/weiqiang/.local/miniconda3/lib/python3.12/site-packages (from netCDF4) (2.3.5)\n",
      "Requirement already satisfied: matplotlib>=3.6 in /Users/weiqiang/.local/miniconda3/lib/python3.12/site-packages (from cartopy) (3.10.8)\n",
      "Requirement already satisfied: shapely>=2.0 in /Users/weiqiang/.local/miniconda3/lib/python3.12/site-packages (from cartopy) (2.1.2)\n",
      "Requirement already satisfied: packaging>=21 in /Users/weiqiang/.local/miniconda3/lib/python3.12/site-packages (from cartopy) (25.0)\n",
      "Requirement already satisfied: pyshp>=2.3 in /Users/weiqiang/.local/miniconda3/lib/python3.12/site-packages (from cartopy) (3.0.3)\n",
      "Requirement already satisfied: pyproj>=3.3.1 in /Users/weiqiang/.local/miniconda3/lib/python3.12/site-packages (from cartopy) (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/weiqiang/.local/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.6->cartopy) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/weiqiang/.local/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.6->cartopy) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/weiqiang/.local/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.6->cartopy) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/weiqiang/.local/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.6->cartopy) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /Users/weiqiang/.local/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.6->cartopy) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Users/weiqiang/.local/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.6->cartopy) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/weiqiang/.local/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.6->cartopy) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/weiqiang/.local/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.6->cartopy) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install netCDF4 cartopy\n",
    "\n",
    "# Download data files\n",
    "import os, tarfile, urllib.request, json\n",
    "data_url = \"https://github.com/AI4EPS/EPS130_Seismology/releases/download/tomography-data/tomography_data.tar.gz\"\n",
    "if not os.path.exists(\"tomography_data\"):\n",
    "    print(\"Downloading tomography data...\")\n",
    "    urllib.request.urlretrieve(data_url, \"tomography_data.tar.gz\")\n",
    "    with tarfile.open(\"tomography_data.tar.gz\") as tf:\n",
    "        tf.extractall()\n",
    "    os.remove(\"tomography_data.tar.gz\")\n",
    "    print(\"Done.\")\n",
    "\n",
    "# Download plate boundary data (Bird, 2003)\n",
    "pb_file = \"tomography_data/PB2002_boundaries.json\"\n",
    "if not os.path.exists(pb_file):\n",
    "    print(\"Downloading plate boundaries...\")\n",
    "    pb_url = \"https://raw.githubusercontent.com/fraxen/tectonicplates/master/GeoJSON/PB2002_boundaries.json\"\n",
    "    urllib.request.urlretrieve(pb_url, pb_file)\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "The cell below defines helper functions. **Just run it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_G(p_values, v_true, dz):\n",
    "    \"\"\"Build the path-length matrix G for 1D layers.\n",
    "    G[i,j] = path length of ray i in layer j.\"\"\"\n",
    "    n_rays, n_layers = len(p_values), len(v_true)\n",
    "    G = np.zeros((n_rays, n_layers))\n",
    "    for i, p in enumerate(p_values):\n",
    "        for j in range(n_layers):\n",
    "            if p >= 1.0 / v_true[j]:\n",
    "                break\n",
    "            cos_theta = np.sqrt(1 - (p * v_true[j])**2)\n",
    "            G[i, j] = 2 * dz[j] / cos_theta\n",
    "    return G\n",
    "\n",
    "def smoothing_matrix_1d(n):\n",
    "    \"\"\"Build 1D smoothing matrix L: differences between adjacent layers.\"\"\"\n",
    "    L = np.zeros((n - 1, n))\n",
    "    for i in range(n - 1):\n",
    "        L[i, i] = -1\n",
    "        L[i, i + 1] = 1\n",
    "    return L\n",
    "\n",
    "def smoothing_matrix_2d(nx, nz):\n",
    "    \"\"\"Build 2D smoothing matrix L: differences between adjacent blocks.\"\"\"\n",
    "    n = nx * nz\n",
    "    rows = []\n",
    "    for iz in range(nz):\n",
    "        for ix in range(nx):\n",
    "            k = iz * nx + ix\n",
    "            if ix < nx - 1:\n",
    "                row = np.zeros(n)\n",
    "                row[k] = -1\n",
    "                row[k + 1] = 1\n",
    "                rows.append(row)\n",
    "            if iz < nz - 1:\n",
    "                row = np.zeros(n)\n",
    "                row[k] = -1\n",
    "                row[k + nx] = 1\n",
    "                rows.append(row)\n",
    "    return np.array(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 1: Forward and Inverse Problem (1D)\n",
    "\n",
    "We have a 4-layer velocity model with 6 rays. The path-length matrix $\\mathbf{G}$ relates the slowness $\\mathbf{m}$ to the travel times $\\mathbf{d}$:\n",
    "\n",
    "$$\\mathbf{d} = \\mathbf{G} \\mathbf{m}$$\n",
    "\n",
    "**(a)** Compute the synthetic travel times (the **forward problem**).\n",
    "\n",
    "**(b)** Recover the slowness from the travel times (the **inverse problem**) using:\n",
    "\n",
    "$$\\mathbf{m} = (\\mathbf{G}^T \\mathbf{G})^{-1} \\mathbf{G}^T \\mathbf{d}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G matrix shape: (6, 4) (6 rays x 4 layers)\n"
     ]
    }
   ],
   "source": [
    "# Set up the 1D model (same as lecture)\n",
    "v_true = np.array([4.0, 5.5, 7.0, 8.0])  # km/s\n",
    "s_true = 1.0 / v_true                      # slowness (s/km)\n",
    "dz = np.array([3.0, 4.0, 5.0, 6.0])       # layer thicknesses (km)\n",
    "n_layers = len(v_true)\n",
    "\n",
    "p_values = np.array([0.02, 0.05, 0.08, 0.10, 0.12, 0.14])  # ray parameters (s/km)\n",
    "n_rays = len(p_values)\n",
    "\n",
    "G = build_G(p_values, v_true, dz)\n",
    "print(f\"G matrix shape: {G.shape} ({n_rays} rays x {n_layers} layers)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (607310025.py, line 3)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31md = ???\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# (a) Forward problem: compute synthetic travel times\n",
    "# d = G @ m (matrix-vector multiplication)\n",
    "d = ???\n",
    "\n",
    "print(\"Synthetic travel times (s):\")\n",
    "for i in range(n_rays):\n",
    "    print(f\"  Ray {i+1} (p={p_values[i]:.2f}): t = {d[i]:.3f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b) Inverse problem: recover slowness from travel times\n",
    "# m = (G^T G)^{-1} G^T d\n",
    "# Hint: use np.linalg.inv() for matrix inverse, and @ for matrix multiplication\n",
    "s_recovered = ???\n",
    "\n",
    "v_recovered = 1.0 / s_recovered\n",
    "\n",
    "print(f\"{'Layer':<8} {'v_true (km/s)':<16} {'v_recovered (km/s)':<20} {'Error (%)':<10}\")\n",
    "for j in range(n_layers):\n",
    "    err = 100 * abs(v_recovered[j] - v_true[j]) / v_true[j]\n",
    "    print(f\"{j+1:<8} {v_true[j]:<16.2f} {v_recovered[j]:<20.4f} {err:<10.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "**Question:** Why is the recovery perfect (error ~ 0%) with no noise? Would it still be perfect if we had only 3 rays instead of 6 (fewer rays than layers)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "*Your answer here:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 2: Effect of Noise and Smoothing (1D)\n",
    "\n",
    "Real data always has noise. When we add noise to the travel times, the undamped inversion can produce wild velocity values. **Regularization** adds a smoothness penalty:\n",
    "\n",
    "$$\\mathbf{m} = (\\mathbf{G}^T \\mathbf{G} + \\alpha^2 \\mathbf{L}^T \\mathbf{L})^{-1} \\mathbf{G}^T \\mathbf{d}$$\n",
    "\n",
    "**(a)** Invert the noisy data **without** smoothing ($\\alpha = 0$).\n",
    "\n",
    "**(b)** Invert with smoothing for three values of $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise to the data\n",
    "np.random.seed(3)\n",
    "noise_level = 0.05  # seconds\n",
    "d_noisy = d + noise_level * np.random.randn(n_rays)\n",
    "\n",
    "# Build the smoothing matrix\n",
    "L1d = smoothing_matrix_1d(n_layers)\n",
    "LtL_1d = L1d.T @ L1d\n",
    "\n",
    "print(f\"Noise level: {noise_level} s\")\n",
    "print(f\"Smoothing matrix L shape: {L1d.shape}\")\n",
    "print(f\"L^T L shape: {LtL_1d.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) Invert WITHOUT smoothing (same formula as Exercise 1, but with noisy data)\n",
    "s_undamped = ???\n",
    "\n",
    "# (b) Invert WITH smoothing for three alpha values\n",
    "alphas = [0.05, 0.5, 50.0]\n",
    "s_smooth = {}\n",
    "for alpha in alphas:\n",
    "    # m = (G^T G + alpha^2 L^T L)^{-1} G^T d\n",
    "    s_smooth[alpha] = ???\n",
    "\n",
    "print(\"Done! Run the next cell to see the results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting (just run this cell)\n",
    "z_interfaces = np.concatenate([[0], np.cumsum(dz)])\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 5), sharey=True)\n",
    "\n",
    "cases = [('Undamped', s_undamped)] + [(f'$\\\\alpha$ = {a}', s_smooth[a]) for a in alphas]\n",
    "for ax, (label, s_inv) in zip(axes, cases):\n",
    "    v_inv = 1.0 / np.clip(s_inv, 1e-6, None)\n",
    "    ax.step(np.concatenate([[v_true[0]], v_true]), z_interfaces, 'k-', lw=2, label='True', where='pre')\n",
    "    ax.step(np.concatenate([[v_inv[0]], v_inv]), z_interfaces, 'r--', lw=2, label='Recovered', where='pre')\n",
    "    ax.set_xlabel('Velocity (km/s)')\n",
    "    ax.set_title(label)\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.set_xlim(0, 12)\n",
    "\n",
    "axes[0].set_ylabel('Depth (km)')\n",
    "axes[0].invert_yaxis()\n",
    "fig.suptitle(f'Effect of smoothing (noise = {noise_level} s)', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "**Question:** As $\\alpha$ increases, the recovered model becomes smoother. But what happens to the data fit (how well $\\mathbf{Gm}$ matches $\\mathbf{d}$)? Why is there a trade-off between fitting the data and smoothness?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "*Your answer here:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 3: 2D Checkerboard Test\n",
    "\n",
    "In 2D, we divide the model into a grid of blocks. The textbook provides a 20$\\times$20 grid with 118 rays. A **checkerboard test** checks how well the inversion can resolve structure: we create a checkerboard model, generate synthetic data, and see if the inversion can recover the pattern.\n",
    "\n",
    "**(a)** Compute synthetic data from the checkerboard model (forward problem).\n",
    "\n",
    "**(b)** Invert the data using the regularized formula.\n",
    "\n",
    "**(c)** Compare results for three different $\\alpha$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load textbook G matrix (just run this cell)\n",
    "nx2, nz2 = 20, 20\n",
    "n_blocks2 = nx2 * nz2\n",
    "\n",
    "gmat_raw = np.loadtxt('tomography_data/tomo_gmat.txt')\n",
    "n_rays2 = int(gmat_raw[:, 0].max())\n",
    "G2 = np.zeros((n_rays2, n_blocks2))\n",
    "for ray_i, mod_j, path_len in gmat_raw:\n",
    "    G2[int(ray_i) - 1, int(mod_j) - 1] = path_len\n",
    "\n",
    "# Build 2D smoothing matrix\n",
    "L2d = smoothing_matrix_2d(nx2, nz2)\n",
    "LtL_2d = L2d.T @ L2d\n",
    "\n",
    "print(f\"Grid: {nx2}x{nz2} = {n_blocks2} blocks\")\n",
    "print(f\"Rays: {n_rays2}\")\n",
    "print(f\"G matrix: {G2.shape}\")\n",
    "print(f\"L^T L: {LtL_2d.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a checkerboard true model (just run this cell)\n",
    "m_checker = np.zeros((nz2, nx2))\n",
    "block_size = 4\n",
    "for iz in range(nz2):\n",
    "    for ix in range(nx2):\n",
    "        if ((iz // block_size) + (ix // block_size)) % 2 == 0:\n",
    "            m_checker[iz, ix] = 1.0\n",
    "        else:\n",
    "            m_checker[iz, ix] = -1.0\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(m_checker, cmap='RdBu', aspect='equal', extent=[0, nx2, nz2, 0], vmin=-1, vmax=1)\n",
    "plt.colorbar(label='Slowness perturbation')\n",
    "plt.title('True checkerboard model')\n",
    "plt.xlabel('Column')\n",
    "plt.ylabel('Row')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) Compute synthetic data: d = G @ m + noise\n",
    "# Note: m_checker is 2D (20x20), but G expects a 1D vector (400,)\n",
    "# Use .ravel() to flatten: m_checker.ravel() converts (20,20) → (400,)\n",
    "noise_level = 5.0\n",
    "np.random.seed(42)\n",
    "\n",
    "d_checker = ???  # G2 @ m_checker.ravel() + noise\n",
    "\n",
    "print(f\"Data vector: {len(d_checker)} travel time perturbations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b) Invert with a single alpha value\n",
    "alpha = 1.0\n",
    "\n",
    "# m = (G^T G + alpha^2 L^T L)^{-1} G^T d\n",
    "m_recovered = ???\n",
    "\n",
    "# Plot true vs recovered\n",
    "fig, axes = plt.subplots(1, 2, figsize=(11, 5), constrained_layout=True)\n",
    "\n",
    "axes[0].imshow(m_checker, cmap='RdBu', aspect='equal',\n",
    "               extent=[0, nx2, nz2, 0], vmin=-1, vmax=1)\n",
    "axes[0].set_title('True checkerboard')\n",
    "\n",
    "axes[1].imshow(m_recovered.reshape(nz2, nx2), cmap='RdBu', aspect='equal',\n",
    "               extent=[0, nx2, nz2, 0], vmin=-1, vmax=1)\n",
    "axes[1].set_title(f'Recovered ($\\\\alpha$={alpha})')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('Column')\n",
    "    ax.set_ylabel('Row')\n",
    "plt.suptitle('Checkerboard test', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c) Compare three different alpha values\n",
    "alpha_values = [0.005, 5.0, 50.0]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(18, 4), constrained_layout=True)\n",
    "\n",
    "axes[0].imshow(m_checker, cmap='RdBu', aspect='equal',\n",
    "               extent=[0, nx2, nz2, 0], vmin=-1, vmax=1)\n",
    "axes[0].set_title('True')\n",
    "axes[0].set_ylabel('Row')\n",
    "\n",
    "for ax, alpha in zip(axes[1:], alpha_values):\n",
    "    # Invert with this alpha\n",
    "    m_rec = ???\n",
    "\n",
    "    im = ax.imshow(m_rec.reshape(nz2, nx2), cmap='RdBu', aspect='equal',\n",
    "                   extent=[0, nx2, nz2, 0], vmin=-1, vmax=1)\n",
    "    ax.set_title(f'$\\\\alpha$ = {alpha}')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('Column')\n",
    "plt.colorbar(im, ax=axes, label='Slowness perturbation', shrink=0.8)\n",
    "fig.suptitle(f'Effect of smoothing (noise = {noise_level})', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "**Question:** Which parts of the 20$\\times$20 grid are best resolved (show a clear checkerboard pattern)? Which parts are poorly resolved? Why? *(Hint: think about where the rays cross.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "*Your answer here:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 4: Invert Real Data\n",
    "\n",
    "Now we use **real** travel time observations from the textbook. The same $\\mathbf{G}$ matrix applies, but instead of synthetic data, we load measured travel time perturbations $\\delta \\mathbf{d}$.\n",
    "\n",
    "**(a)** Invert the real data with $\\alpha = 1.0$.\n",
    "\n",
    "**(b)** Try four different $\\alpha$ values and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load real travel time data (just run this cell)\n",
    "data_raw = np.loadtxt('tomography_data/tomo_data.txt')\n",
    "d2 = data_raw[:, 1]\n",
    "print(f\"Data: {len(d2)} travel time perturbations, {np.sum(d2 != 0)} non-zero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) Invert the real data with alpha = 1.0\n",
    "alpha = 1.0\n",
    "\n",
    "m_real = ???\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.imshow(m_real.reshape(nz2, nx2).T, cmap='RdBu', aspect='equal',\n",
    "           extent=[0, nx2, nz2, 0])\n",
    "plt.colorbar(label='Slowness perturbation')\n",
    "plt.title(f'Real data inversion ($\\\\alpha$ = {alpha})')\n",
    "plt.xlabel('Column')\n",
    "plt.ylabel('Row')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b) Compare four different alpha values\n",
    "alpha_values = [0.1, 1.0, 5.0, 20.0]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(18, 4), constrained_layout=True)\n",
    "\n",
    "for ax, alpha in zip(axes, alpha_values):\n",
    "    m_rec = ???\n",
    "\n",
    "    vmax = np.percentile(np.abs(m_rec), 95)\n",
    "    im = ax.imshow(m_rec.reshape(nz2, nx2).T, cmap='RdBu', aspect='equal',\n",
    "                   extent=[0, nx2, nz2, 0], vmin=-vmax, vmax=vmax)\n",
    "    ax.set_title(f'$\\\\alpha$ = {alpha}')\n",
    "    ax.set_xlabel('Column')\n",
    "\n",
    "axes[0].set_ylabel('Row')\n",
    "plt.colorbar(im, ax=axes, label='Slowness perturbation', shrink=0.8)\n",
    "fig.suptitle('Real data inversion: effect of smoothing', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "**Question:** Which features appear consistently across different $\\alpha$ values? Those are the most robust. Which features change a lot with $\\alpha$? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "*Your answer here:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 5: Interpreting Global Tomography\n",
    "\n",
    "The cells below plot depth slices from two real tomography models:\n",
    "- **S362ANI**: global shear-wave velocity ($\\delta V_s / V_s$)\n",
    "- **MITPS-20**: P-wave velocity beneath North America ($\\delta V_p / V_p$)\n",
    "\n",
    "**Just run the plotting cells**, then answer the interpretation questions below.\n",
    "\n",
    "Recall: **Blue = fast** (cold material), **Red = slow** (hot material)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load S362ANI global model (just run this cell)\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import netCDF4 as nc\n",
    "\n",
    "ds = nc.Dataset('tomography_data/S362ANI_percent.nc')\n",
    "lat = ds.variables['latitude'][:]\n",
    "lon = ds.variables['longitude'][:]\n",
    "depth = ds.variables['depth'][:]\n",
    "dvs = np.ma.filled(ds.variables['dvs'][:], fill_value=np.nan)\n",
    "\n",
    "with open('tomography_data/PB2002_boundaries.json') as f:\n",
    "    pb_data = json.load(f)\n",
    "\n",
    "def plot_plate_boundaries(ax, color='k', lw=0.8, alpha=0.6):\n",
    "    for feature in pb_data['features']:\n",
    "        coords = feature['geometry']['coordinates']\n",
    "        if feature['geometry']['type'] == 'LineString':\n",
    "            coords = [coords]\n",
    "        for segment in coords:\n",
    "            lons, lats = zip(*segment)\n",
    "            ax.plot(lons, lats, '-', color=color, lw=lw, alpha=alpha,\n",
    "                    transform=ccrs.PlateCarree())\n",
    "\n",
    "print(f\"S362ANI: {len(lat)} lat x {len(lon)} lon x {len(depth)} depths\")\n",
    "print(f\"Depths (km): {depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot S362ANI depth slices (just run this cell)\n",
    "depth_slices = [100, 250, 600, 2800]\n",
    "LON, LAT = np.meshgrid(lon, lat)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10),\n",
    "                         subplot_kw={'projection': ccrs.Robinson()})\n",
    "\n",
    "for ax, target_depth in zip(axes.ravel(), depth_slices):\n",
    "    iz = np.argmin(np.abs(depth - target_depth))\n",
    "    data = dvs[iz]\n",
    "    vmax = np.nanpercentile(np.abs(data), 98)\n",
    "\n",
    "    im = ax.pcolormesh(LON, LAT, data, cmap='RdBu', vmin=-vmax, vmax=vmax,\n",
    "                       transform=ccrs.PlateCarree(), shading='auto')\n",
    "    ax.coastlines(lw=0.5)\n",
    "    plot_plate_boundaries(ax)\n",
    "    ax.set_title(f'Depth = {depth[iz]:.0f} km', fontsize=12)\n",
    "    plt.colorbar(im, ax=ax, orientation='horizontal', pad=0.05,\n",
    "                 label='$\\\\delta V_s / V_s$ (%)', shrink=0.7)\n",
    "\n",
    "fig.suptitle('S362ANI: Global shear-wave velocity perturbations', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phlgxbkgluq",
   "metadata": {},
   "source": [
    "**(a)** Look at the S362ANI map at **100 km** depth. Where are the fast (blue) anomalies? Where are the slow (red) anomalies? Why are continents generally fast at this depth?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73k4nlfeck",
   "metadata": {},
   "source": [
    "*Your answer here:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yrmmi27dfob",
   "metadata": {},
   "source": [
    "**(b)** Look at the S362ANI map at **600 km** depth. Can you identify any fast anomalies that might be subducting slabs? Where are they?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jdqfyfqylbj",
   "metadata": {},
   "source": [
    "*Your answer here:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qnxl7ay2gjr",
   "metadata": {},
   "source": [
    "**(c)** Look at the S362ANI map at **2800 km** depth (near the core-mantle boundary). Describe the large-scale pattern. Where are the two large slow regions (LLSVPs)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iqff0he0t5",
   "metadata": {},
   "source": [
    "*Your answer here:*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
